{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pymannkendall as mk\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting the discharge files as a mean to get all relevant catchment names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['200013',\n",
       " '200032',\n",
       " '200142',\n",
       " '200268',\n",
       " '200279',\n",
       " '200284',\n",
       " '200290',\n",
       " '200303',\n",
       " '200323',\n",
       " '600010',\n",
       " '1200070',\n",
       " '1200171',\n",
       " '1200178',\n",
       " '1200193',\n",
       " '1500049',\n",
       " '1600066',\n",
       " '1600075',\n",
       " '1800010',\n",
       " '1800011',\n",
       " '1900079',\n",
       " '1900080',\n",
       " '1900082',\n",
       " '1900096',\n",
       " '1900104',\n",
       " '2000002',\n",
       " '2000011',\n",
       " '2200016',\n",
       " '2400008',\n",
       " '2400009',\n",
       " '2500024',\n",
       " '2600020',\n",
       " '2600021',\n",
       " '3600013',\n",
       " '4100001',\n",
       " '4100008',\n",
       " '4200002',\n",
       " '4800005',\n",
       " '5000001',\n",
       " '5000013',\n",
       " '5500004',\n",
       " '6200005',\n",
       " '6200010',\n",
       " '6200014',\n",
       " '6200015',\n",
       " '7500023',\n",
       " '7500028',\n",
       " '7600005',\n",
       " '7800008',\n",
       " '7900003',\n",
       " '8000004',\n",
       " '8100001',\n",
       " '8200004',\n",
       " '8300002',\n",
       " '8300006',\n",
       " '8300007',\n",
       " '8300012',\n",
       " '8400011',\n",
       " '8400020',\n",
       " '8500004',\n",
       " '8600010',\n",
       " '8600012',\n",
       " '8700010',\n",
       " '8800004',\n",
       " '8800011',\n",
       " '9100002',\n",
       " '9700001',\n",
       " '9800004',\n",
       " '10100001',\n",
       " '10400022',\n",
       " '10400023',\n",
       " '10500001',\n",
       " '10900009',\n",
       " '11200008',\n",
       " '12200011',\n",
       " '12300031',\n",
       " '12400002',\n",
       " '12700006',\n",
       " '12700011',\n",
       " '12700013',\n",
       " '12800005',\n",
       " '13300007',\n",
       " '13800001',\n",
       " '13900020',\n",
       " '13900026',\n",
       " '13900035',\n",
       " '14000002',\n",
       " '14800002',\n",
       " '15100015',\n",
       " '15200004',\n",
       " '15300001',\n",
       " '15600008',\n",
       " '15600010',\n",
       " '15600015',\n",
       " '16300007',\n",
       " '16800003',\n",
       " '17200007',\n",
       " '17200008',\n",
       " '17700004',\n",
       " '17800001',\n",
       " '18500001',\n",
       " '19100002',\n",
       " '19600007',\n",
       " '19600011',\n",
       " '20000004',\n",
       " '20500006',\n",
       " '20600003',\n",
       " '20800002',\n",
       " '20800003',\n",
       " '20900004',\n",
       " '21200010',\n",
       " '21200049',\n",
       " '21300002',\n",
       " '21300004',\n",
       " '22300002',\n",
       " '23400018',\n",
       " '24400002',\n",
       " '24600009',\n",
       " '24700003',\n",
       " '30700005',\n",
       " '30700007',\n",
       " '30800001',\n",
       " '31100004',\n",
       " '31100460',\n",
       " '31300010']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirl  = \"Final_dataset/\"\n",
    "files = os.listdir(dirl)\n",
    "files = np.sort(files)\n",
    "files_txt = [i for i in files if i.endswith('.txt_')]\n",
    "\n",
    "files_txt = [i[:-5] for i in files if i.endswith('.txt_')]\n",
    "files_txt.sort(key=int)\n",
    "files_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing catchments and adding it to the end of the list to correspond the list to the one in my_dc_dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_txt.remove('20000004')\n",
    "len(files_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_txt.append('20000004')\n",
    "len(files_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename list of files to catchments names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "for i in files_txt:\n",
    "    new_list.append(i[0:-5]+'.'+i[-5:])\n",
    "re_zero = r\"[0]{2,4}\"\n",
    "removed_zeros = []\n",
    "for i in new_list:\n",
    "    j = i+\".0\"\n",
    "    removed_zeros.append(re.sub(re_zero, \"\", j))\n",
    "\n",
    "removed_zeros.append('200.4.0')\n",
    "removed_zeros.remove('2.4.0')\n",
    "\n",
    "#print(removed_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of reading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>185.1.0</th>\n",
       "      <th>246.9.0</th>\n",
       "      <th>213.4.0</th>\n",
       "      <th>140.2.0</th>\n",
       "      <th>127.6.0</th>\n",
       "      <th>168.3.0</th>\n",
       "      <th>20.11.0</th>\n",
       "      <th>80.4.0</th>\n",
       "      <th>88.11.0</th>\n",
       "      <th>177.4.0</th>\n",
       "      <th>191.2.0</th>\n",
       "      <th>200.4.0</th>\n",
       "      <th>127.11.0</th>\n",
       "      <th>50.1.0</th>\n",
       "      <th>20.2.0</th>\n",
       "      <th>62.10.0</th>\n",
       "      <th>234.18.0</th>\n",
       "      <th>2.142.0</th>\n",
       "      <th>122.11.0</th>\n",
       "      <th>123.31.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-01</th>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.333334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.242424</td>\n",
       "      <td>2.614943</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-02</th>\n",
       "      <td>4.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.703704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.036398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-03</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-04</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-05</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-27</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.789366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.369266</td>\n",
       "      <td>0.550432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>1.128834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150289</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>0.584838</td>\n",
       "      <td>1.944099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000610</td>\n",
       "      <td>0.047256</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.422018</td>\n",
       "      <td>0.567723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.128834</td>\n",
       "      <td>0.484849</td>\n",
       "      <td>0.455939</td>\n",
       "      <td>0.067164</td>\n",
       "      <td>0.433526</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.549390</td>\n",
       "      <td>0.112805</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.922018</td>\n",
       "      <td>0.096542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.231343</td>\n",
       "      <td>0.028902</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.176895</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.353049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11323 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            185.1.0  246.9.0   213.4.0   140.2.0   127.6.0   168.3.0  20.11.0  \\\n",
       "time                                                                            \n",
       "1990-01-01     9.00      0.0  0.352459  0.000000  0.000000  4.333334      NaN   \n",
       "1990-01-02     4.25      0.0  0.000000  0.000000  0.000000  1.703704      NaN   \n",
       "1990-01-03     0.00      0.0  0.000000  0.000000  0.000000  0.000000      NaN   \n",
       "1990-01-04     0.00      0.0  0.000000  0.000000  0.000000  0.000000      NaN   \n",
       "1990-01-05     0.00      0.0  0.000000  0.000000  0.000000  0.000000      NaN   \n",
       "...             ...      ...       ...       ...       ...       ...      ...   \n",
       "2020-12-27     0.00      0.0  0.000000  0.000000  0.000000  0.000000      NaN   \n",
       "2020-12-28     0.00      0.0  0.000000  4.369266  0.550432  0.000000      NaN   \n",
       "2020-12-29     0.00      0.0  0.000000  1.422018  0.567723  0.000000      NaN   \n",
       "2020-12-30     0.00      0.0  0.000000  0.922018  0.096542  0.000000      NaN   \n",
       "2020-12-31     0.00      0.0  0.000000  0.000000  0.000000  0.000000      NaN   \n",
       "\n",
       "              80.4.0   88.11.0   177.4.0   191.2.0   200.4.0  127.11.0  \\\n",
       "time                                                                     \n",
       "1990-01-01  0.000000  0.000000  5.242424  2.614943  3.500000  0.000000   \n",
       "1990-01-02  0.000000  0.000000  0.969697  0.036398  0.000000  0.000000   \n",
       "1990-01-03  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1990-01-04  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1990-01-05  0.000000  0.000000  1.333333  0.000000  0.000000  0.000000   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2020-12-27  0.000000  0.789366  0.000000  0.000000  0.000000  0.000000   \n",
       "2020-12-28  7.714286  1.128834  0.000000  0.000000  0.000000  0.150289   \n",
       "2020-12-29  0.285714  0.128834  0.484849  0.455939  0.067164  0.433526   \n",
       "2020-12-30  0.857143  0.040900  0.212121  0.017241  0.231343  0.028902   \n",
       "2020-12-31  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "              50.1.0    20.2.0   62.10.0  234.18.0   2.142.0  122.11.0  \\\n",
       "time                                                                     \n",
       "1990-01-01  0.000000  0.000000  0.000000       0.0  0.000000  0.000000   \n",
       "1990-01-02  0.000000  0.000000  0.000000       0.0  0.000000  0.000000   \n",
       "1990-01-03  0.000000  0.000000  0.000000       0.0  0.000000  0.000000   \n",
       "1990-01-04  0.000000  0.000000  0.000000       0.0  0.000000  0.000000   \n",
       "1990-01-05  0.000000  0.000000  0.000000       0.0  0.000000  0.000000   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2020-12-27  0.232759  0.000000  1.043478       0.0  0.000000  0.000000   \n",
       "2020-12-28  0.155172  0.584838  1.944099       0.0  2.000610  0.047256   \n",
       "2020-12-29  0.004310  0.000000  0.409938       0.0  0.549390  0.112805   \n",
       "2020-12-30  0.004310  0.176895  0.142857       0.0  1.353049  0.000000   \n",
       "2020-12-31  0.000000  0.007220  0.000000       0.0  0.000000  0.000000   \n",
       "\n",
       "            123.31.0  \n",
       "time                  \n",
       "1990-01-01  0.000000  \n",
       "1990-01-02  0.000000  \n",
       "1990-01-03  0.000000  \n",
       "1990-01-04  0.000000  \n",
       "1990-01-05  0.000000  \n",
       "...              ...  \n",
       "2020-12-27  0.000000  \n",
       "2020-12-28  0.400000  \n",
       "2020-12-29  0.528571  \n",
       "2020-12-30  0.000000  \n",
       "2020-12-31  0.000000  \n",
       "\n",
       "[11323 rows x 20 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow_variable = pd.read_csv('ferige_ssenorge/qtt_runoff_amount/runoff_amount/combined_'+'runoff_amount'+'_del2.csv', index_col=0)\n",
    "snow_variable_sorted = snow_variable.sort_index()\n",
    "snow_variable_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating mean yearly values of each snow or evaporation value, and then calculating trends over these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SD - Snow depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This station was skipped: 2.290.0\n",
      "This station was skipped: 18.11.0\n",
      "This station was skipped: 20.11.0\n",
      "This station was skipped: 41.8.0\n",
      "This station was skipped: 62.14.0\n",
      "This station was skipped: 62.15.0\n",
      "This station was skipped: 83.6.0\n",
      "This station was skipped: 83.7.0\n",
      "This station was skipped: 83.12.0\n",
      "This station was skipped: 311.4.0\n"
     ]
    }
   ],
   "source": [
    "inner_path = 'snow_depth'\n",
    "short = 'sd'\n",
    "\n",
    "snow_variable_type1 = pd.read_csv('ferige_ssenorge/'+short+'_'+inner_path+'/combined_'+inner_path+'.csv', index_col=0)\n",
    "snow_variable_sorted1 = snow_variable_type1.sort_index()\n",
    "\n",
    "snow_variable_type2 = pd.read_csv('ferige_ssenorge/'+short+'_'+inner_path+'/'+inner_path+'/combined_'+inner_path+'_del2.csv', index_col=0)\n",
    "snow_variable_sorted2 = snow_variable_type2.sort_index()\n",
    "\n",
    "bigdata = pd.concat([snow_variable_sorted1, snow_variable_sorted2],  sort=False, axis=1)\n",
    "\n",
    "bigdata['Datetime'] = pd.to_datetime(bigdata.index, format='%Y-%m-%d')\n",
    "bigdata = bigdata.set_index('Datetime')\n",
    "\n",
    "myperiod = bigdata['1990':'2020']\n",
    "myperiod = myperiod.loc[:,~myperiod.columns.duplicated(keep='last')]\n",
    "\"\"\"\n",
    "re_zero = r\"[0]{2,4}\"\n",
    "removed_zeros = []\n",
    "snow_depth_trend_max = []\n",
    "for i in files_txt:\n",
    "    j = i+\".0\"\n",
    "    removed_zeros.append(re.sub(re_zero, \".\", j))\n",
    "\n",
    "snow_variable = pd.read_csv(inner_path+'/combined_'+inner_path+'.csv', index_col=0)\n",
    "snow_variable_sorted = snow_variable.sort_index()\n",
    "snow_variable_sorted.index = pd.to_datetime(snow_variable_sorted.index,format=\"%Y-%m-%d\") \n",
    "\"\"\"\n",
    "snow_variable_yr = myperiod.resample('12MS').max()\n",
    "\n",
    "yearly_trend_result = []\n",
    "trend_do_not_exist = []\n",
    "snow_depth_mean =[]\n",
    "\n",
    "for i in removed_zeros:\n",
    "    try:\n",
    "        alltrendm = mk.original_test(snow_variable_yr[i])\n",
    "        if alltrendm.trend=='increasing':\n",
    "            yearly_trend_result.append(1)\n",
    "        elif alltrendm.trend=='no trend':\n",
    "            yearly_trend_result.append(0)\n",
    "        else:\n",
    "            yearly_trend_result.append(-1)\n",
    "    except:\n",
    "            trend_do_not_exist.append(i)\n",
    "            yearly_trend_result.append('NaN')\n",
    "            print('This station was skipped:', i)\n",
    "            continue   \n",
    "snow_depth_trend_max =yearly_trend_result\n",
    "#snow_depth_max.index = removed_zeros\n",
    "#snow_depth_trend_max\n",
    "len(snow_depth_trend_max)\n",
    "\n",
    "for i in removed_zeros:\n",
    "    a = snow_variable_yr[i].mean()\n",
    "    snow_depth_mean.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SWE - rekna ut mean for kvar vinterperiode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This station was skipped: 2.290.0\n",
      "This station was skipped: 18.11.0\n",
      "This station was skipped: 20.11.0\n",
      "This station was skipped: 41.8.0\n",
      "This station was skipped: 62.14.0\n",
      "This station was skipped: 62.15.0\n",
      "This station was skipped: 83.6.0\n",
      "This station was skipped: 83.7.0\n",
      "This station was skipped: 83.12.0\n",
      "This station was skipped: 311.4.0\n"
     ]
    }
   ],
   "source": [
    "inner_path = 'snow_water_equivalent'\n",
    "short = 'swe'\n",
    "\n",
    "snow_variable_type1 = pd.read_csv('ferige_ssenorge/'+short+'_'+inner_path+'/combined_'+inner_path+'.csv', index_col=0)\n",
    "snow_variable_sorted1 = snow_variable_type1.sort_index()\n",
    "\n",
    "snow_variable_type2 = pd.read_csv('ferige_ssenorge/'+short+'_'+inner_path+'/'+inner_path+'/combined_'+inner_path+'_del2.csv', index_col=0)\n",
    "snow_variable_sorted2 = snow_variable_type2.sort_index()\n",
    "\n",
    "bigdata = pd.concat([snow_variable_sorted1, snow_variable_sorted2],  sort=False, axis=1)\n",
    "\n",
    "bigdata['Datetime'] = pd.to_datetime(bigdata.index, format='%Y-%m-%d')\n",
    "bigdata = bigdata.set_index('Datetime')\n",
    "\n",
    "myperiod = bigdata['1990':'2020']\n",
    "myperiod = myperiod.loc[:,~myperiod.columns.duplicated(keep='last')]\n",
    "\"\"\"\n",
    "re_zero = r\"[0]{2,4}\"\n",
    "removed_zeros = []\n",
    "snow_depth_trend_max = []\n",
    "for i in files_txt:\n",
    "    j = i+\".0\"\n",
    "    removed_zeros.append(re.sub(re_zero, \".\", j))\n",
    "\n",
    "snow_variable = pd.read_csv(inner_path+'/combined_'+inner_path+'.csv', index_col=0)\n",
    "snow_variable_sorted = snow_variable.sort_index()\n",
    "snow_variable_sorted.index = pd.to_datetime(snow_variable_sorted.index,format=\"%Y-%m-%d\") \n",
    "\"\"\"\n",
    "snow_variable_yr = myperiod.resample('12MS').mean()\n",
    "\n",
    "yearly_trend_result = []\n",
    "trend_do_not_exist = []\n",
    "swe_mean_yr =[]\n",
    "\n",
    "for i in removed_zeros:\n",
    "    try:\n",
    "        alltrendm = mk.original_test(snow_variable_yr[i])\n",
    "        if alltrendm.trend=='increasing':\n",
    "            yearly_trend_result.append(1)\n",
    "        elif alltrendm.trend=='no trend':\n",
    "            yearly_trend_result.append(0)\n",
    "        else:\n",
    "            yearly_trend_result.append(-1)\n",
    "    except:\n",
    "            trend_do_not_exist.append(i)\n",
    "            yearly_trend_result.append('NaN')\n",
    "            print('This station was skipped:', i)\n",
    "            continue   \n",
    "swe_mean =yearly_trend_result\n",
    "#snow_depth_max.index = removed_zeros\n",
    "len(swe_mean)\n",
    "\n",
    "for i in removed_zeros:\n",
    "    a = snow_variable_yr[i].mean()\n",
    "    swe_mean_yr.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QSW - snow melt, mean for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This station was skipped: 2.290.0\n",
      "This station was skipped: 18.11.0\n",
      "This station was skipped: 20.11.0\n",
      "This station was skipped: 41.8.0\n",
      "This station was skipped: 62.14.0\n",
      "This station was skipped: 62.15.0\n",
      "This station was skipped: 83.6.0\n",
      "This station was skipped: 83.7.0\n",
      "This station was skipped: 83.12.0\n",
      "This station was skipped: 311.4.0\n"
     ]
    }
   ],
   "source": [
    "inner_path = 'snow_melt'\n",
    "short = 'qsw'\n",
    "snow_variable_type1 = pd.read_csv('ferige_ssenorge/'+short+'_'+inner_path+'/combined_'+inner_path+'.csv', index_col=0)\n",
    "snow_variable_sorted1 = snow_variable_type1.sort_index()\n",
    "snow_variable_type2 = pd.read_csv('ferige_ssenorge/'+short+'_'+inner_path+'/'+inner_path+'/combined_'+inner_path+'_del2.csv', index_col=0)\n",
    "snow_variable_sorted2 = snow_variable_type2.sort_index()\n",
    "bigdata = pd.concat([snow_variable_sorted1, snow_variable_sorted2],  sort=False, axis=1)\n",
    "\n",
    "bigdata['Datetime'] = pd.to_datetime(bigdata.index, format='%Y-%m-%d')\n",
    "bigdata = bigdata.set_index('Datetime')\n",
    "\n",
    "myperiod = bigdata['1990':'2020']\n",
    "myperiod = myperiod.loc[:,~myperiod.columns.duplicated(keep='last')]\n",
    "\n",
    "snow_variable_yr = myperiod.resample('12MS').mean()\n",
    "\n",
    "yearly_trend_result = []\n",
    "trend_do_not_exist = []\n",
    "qsw_mean_yr=[]\n",
    "\n",
    "for i in removed_zeros:\n",
    "    try:\n",
    "        alltrendm = mk.original_test(snow_variable_yr[i])\n",
    "        if alltrendm.trend=='increasing':\n",
    "            yearly_trend_result.append(1)\n",
    "        elif alltrendm.trend=='no trend':\n",
    "            yearly_trend_result.append(0)\n",
    "        else:\n",
    "            yearly_trend_result.append(-1)\n",
    "    except:\n",
    "            trend_do_not_exist.append(i)\n",
    "            yearly_trend_result.append('NaN')\n",
    "            print('This station was skipped:', i)\n",
    "            continue   \n",
    "qsw_mean =yearly_trend_result\n",
    "#snow_depth_max.index = removed_zeros\n",
    "len(qsw_mean)\n",
    "\n",
    "for i in removed_zeros:\n",
    "    a = snow_variable_yr[i].mean()\n",
    "    qsw_mean_yr.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Water evaporation amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This station was skipped: 20.11.0\n",
      "This station was skipped: 62.14.0\n",
      "This station was skipped: 83.7.0\n"
     ]
    }
   ],
   "source": [
    "inner_path = 'water_evaporation_amount'\n",
    "short = 'gwb_eva'\n",
    "snow_variable_type1 = pd.read_csv('ferige_ssenorge/'+short+'_'+inner_path+'/combined_'+inner_path+'.csv', index_col=0)\n",
    "snow_variable_sorted1 = snow_variable_type1.sort_index()\n",
    "snow_variable_type2 = pd.read_csv('ferige_ssenorge/'+short+'_'+inner_path+'/'+inner_path+'/combined_'+inner_path+'_del2.csv', index_col=0)\n",
    "snow_variable_sorted2 = snow_variable_type2.sort_index()\n",
    "bigdata = pd.concat([snow_variable_sorted1, snow_variable_sorted2],  sort=False, axis=1)\n",
    "\n",
    "bigdata['Datetime'] = pd.to_datetime(bigdata.index, format='%Y-%m-%d')\n",
    "bigdata = bigdata.set_index('Datetime')\n",
    "\n",
    "myperiod = bigdata['1990':'2020']\n",
    "myperiod = myperiod.loc[:,~myperiod.columns.duplicated(keep='last')]\n",
    "\n",
    "#snow_variable_yr = myperiod.resample('12MS').mean()\n",
    "snow_variable_yr = myperiod.resample('12M').mean()\n",
    "\n",
    "yearly_trend_result = []\n",
    "trend_do_not_exist = []\n",
    "gwb_eva_mean_yr = []\n",
    "\n",
    "for i in removed_zeros:\n",
    "    try:\n",
    "        alltrendm = mk.original_test(snow_variable_yr[i])\n",
    "        if alltrendm.trend=='increasing':\n",
    "            yearly_trend_result.append(1)\n",
    "        elif alltrendm.trend=='no trend':\n",
    "            yearly_trend_result.append(0)\n",
    "        else:\n",
    "            yearly_trend_result.append(-1)\n",
    "    except:\n",
    "            trend_do_not_exist.append(i)\n",
    "            yearly_trend_result.append('NaN')\n",
    "            print('This station was skipped:', i)\n",
    "            continue   \n",
    "gwb_eva_mean =yearly_trend_result\n",
    "#snow_depth_max.index = removed_zeros\n",
    "len(gwb_eva_mean)\n",
    "\n",
    "for i in removed_zeros:\n",
    "    a = snow_variable_yr[i].mean()\n",
    "    gwb_eva_mean_yr.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd23b12d419dedc7182a77b70ff5b5bd62b35d813df10a2a0458dd3d3165a7b1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('py39': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
